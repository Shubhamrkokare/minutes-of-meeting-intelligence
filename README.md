# ğŸ§  Minutes of Meeting Intelligence System

An end-to-end AI system that converts raw meeting audio into structured **Minutes of Meeting (MoM)** with summaries, action items, and sentiment insights â€” delivered through an interactive dashboard.

---

## ğŸš€ Overview

This project automates the complete post-meeting documentation workflow by combining **speech recognition**, **LLM-based reasoning**, and **fine-tuned summarization models**.

Given a meeting audio file, the system:
- Transcribes speech to text
- Structures conversation context
- Generates concise MoM summaries
- Extracts action items
- Performs sentiment analysis
- Presents results in a professional Streamlit dashboard

---

## ğŸ§© System Architecture

Audio File
â†“
Speech-to-Text (Whisper)
â†“
Conversation Structuring (LLM)
â†“
Summarization (Fine-tuned BART + LoRA)
â†“
Action Item Extraction
â†“
Sentiment Analysis
â†“
Streamlit Dashboard + Artifacts


Each run is isolated and stored inside a timestamped `runs/` directory for traceability.

---

## ğŸ”§ Tech Stack

### Core Technologies
- **Python**
- **Streamlit** â€“ Interactive dashboard
- **OpenAI Whisper** â€“ Speech-to-text transcription
- **BART (facebook/bart-large-cnn)** â€“ Summarization
- **LoRA (PEFT)** â€“ Parameter-efficient fine-tuning
- **NLTK (VADER)** â€“ Sentiment analysis
- **Gemini API** â€“ Conversation structuring & reasoning

### ML & NLP
- Hugging Face Transformers
- PEFT (LoRA)
- DialogSum dataset (for fine-tuning)

---

## ğŸ“ Project Structure

Minutes of Meetings/
â”‚
â”œâ”€â”€ dashboard/
â”‚ â””â”€â”€ app.py # Streamlit UI
â”‚
â”œâ”€â”€ models/
â”‚ â””â”€â”€ bart_dialogsum_lora/ # Fine-tuned LoRA adapters
â”‚
â”œâ”€â”€ runs/
â”‚ â””â”€â”€ run_<timestamp>/ # Per-run artifacts
â”‚
â”œâ”€â”€ audtoscript.py # Whisper transcription
â”œâ”€â”€ conversation_builder.py # Conversation structuring
â”œâ”€â”€ summarizer.py # BART-based summarization
â”œâ”€â”€ action_items.py # Action item extraction
â”œâ”€â”€ sentiment_analysis.py # Sentiment scoring
â”œâ”€â”€ pipeline.py # End-to-end pipeline
â”œâ”€â”€ pdf_generator.py # PDF export (optional)
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md


---

## ğŸ§ª How It Works (Pipeline)

1. **Audio Upload**
   - User uploads `.mp3` or `.wav` file via dashboard

2. **Transcription**
   - Whisper converts audio â†’ raw transcript

3. **Conversation Structuring**
   - Transcript is structured into speaker-aware dialogue

4. **Summarization**
   - Fine-tuned BART (LoRA) generates MoM-style summary

5. **Action Item Extraction**
   - Tasks, responsibilities, and follow-ups are identified

6. **Sentiment Analysis**
   - Overall and detailed sentiment scores are computed

7. **Results Display**
   - Output shown in Streamlit UI
   - Artifacts stored in `runs/`

---

## ğŸ–¥ï¸ Dashboard Features

- Audio upload & validation
- Real-time processing feedback
- Clean MoM summary view
- Action item section
- Sentiment indicators
- Run metadata & artifact tracking

---

## âš™ï¸ Setup Instructions

### 1ï¸âƒ£ Clone Repository
```bash
git clone https://github.com/<your-username>/minutes-of-meeting-intelligence.git
cd minutes-of-meeting-intelligence

2ï¸âƒ£ Create Virtual Environment
        python -m venv .venv
        .\.venv\Scripts\Activate.ps1   # Windows

3ï¸âƒ£ Install Dependencies
        pip install -r requirements.txt

4ï¸âƒ£ Run Dashboard
        streamlit run dashboard/app.py
